{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vikram Anand\n",
    "## 21105129"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining file path\n",
    "##### p = \"folderpath\" and adding '/' to open the folder to get to the jpg files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"E:\\\\MTech\\\\2nd Sem\\\\ME698G (DL)\\\\Assignment\\\\A2\\\\train\" + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defination for Preprocessing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(folder, dimension):\n",
    "    pr_data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        label=None\n",
    "        try:\n",
    "            x = cv2.imread(folder+'{0}'.format(filename),cv2.IMREAD_GRAYSCALE)\n",
    "            feature = np.array(cv2.resize(x, dimension))\n",
    "            fd, hog_img = hog(feature, orientations = 9, pixels_per_cell= (8, 8), cells_per_block=(2,2,),visualize = True)\n",
    "            features = hog_img.flatten()\n",
    "        except Exception as e:\n",
    "            print(str(e))     \n",
    "        \n",
    "        if (filename[0:3]==\"cat\")==True:   \n",
    "            label = 0\n",
    "        elif (filename[0:3]==\"dog\")==True: \n",
    "            label = 1                        \n",
    "        else :\n",
    "          label = None\n",
    "          \n",
    "        pr_data.append(np.hstack(np.array([features, label],dtype=object)))\n",
    "        \n",
    "    data = np.vstack(pr_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the images and creating array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = (128,64 )\n",
    "data = preprocessing(p,dimension)\n",
    "X,Y = data[:,:-1],data[:,-1]\n",
    "ss = StandardScaler()\n",
    "a = ss.fit_transform(X)\n",
    "b = Y\n",
    "print('Shape of a is: ', a.shape)\n",
    "print('Shape of b is: ', b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting data into train and test data\n",
    "##### 30 % of data to test data & 70 % to train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(a, b, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition to compare Prediction for random entry from Test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vs_pred(test_labels,prediction):    \n",
    "    i=np.random.randint(len(test_labels))\n",
    "    if test_labels[i]==1:\n",
    "        print('Randomly selected output from Test data = Dog')\n",
    "    elif test_labels[i]==0:\n",
    "        print('Randomly selected output from Test data = Cat')\n",
    "    if prediction[i]==1:\n",
    "        print('Prediction for that output = Dog')\n",
    "    elif prediction[i]==0:\n",
    "        print('Prediction for that output = Cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour (KNN) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=30)\n",
    "knn.fit(train_features,train_labels)\n",
    "pred = knn.predict(test_features)\n",
    "accuracy = knn.score(test_features,test_labels)\n",
    "con = metrics.confusion_matrix(test_labels,pred)\n",
    "print('Accuracy = ', accuracy*100,'%')\n",
    "print(pred)\n",
    "print(test_labels)\n",
    "test_vs_pred(test_labels,pred)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.matshow(con, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(con.shape[0]):\n",
    "    for j in range(con.shape[1]):\n",
    "        ax.text(x=j, y=i, s=con[i,j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=10)\n",
    "plt.ylabel('Actuals', fontsize=10)\n",
    "plt.title('Confusion Matrix', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (LR) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C = 0.00001,solver='liblinear', max_iter=1000)\n",
    "LR.fit(train_features,train_labels)\n",
    "predl = LR.predict(test_features)\n",
    "accuracyl = LR.score(test_features,test_labels)\n",
    "print('Accuracy = ', accuracyl*100,'%')\n",
    "print(predl)\n",
    "print(test_labels)\n",
    "test_vs_pred(test_labels,predl)\n",
    "conl = metrics.confusion_matrix(test_labels,predl)\n",
    "figl, axl = plt.subplots(figsize=(5,5))\n",
    "axl.matshow(conl, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conl.shape[0]):\n",
    "    for j in range(conl.shape[1]):\n",
    "        axl.text(x=j, y=i, s=conl[i,j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=10)\n",
    "plt.ylabel('Actuals', fontsize=10)\n",
    "plt.title('Confusion Matrix', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier (SVC) implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcl = LinearSVC(penalty=\"l2\", loss=\"squared_hinge\", dual=True, tol=0.0001, C=0.00001, multi_class=\"ovr\", fit_intercept=True, intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=20000)\n",
    "svcl.fit(train_features,train_labels)\n",
    "predn = svcl.predict(test_features)\n",
    "accuracyn = svcl.score(test_features,test_labels)\n",
    "conn = metrics.confusion_matrix(test_labels,predn)\n",
    "print('Accuracy = ', accuracyn*100,'%')\n",
    "print(predn)\n",
    "print(test_labels)\n",
    "test_vs_pred(test_labels,predn)\n",
    "fign, axn = plt.subplots(figsize=(5,5))\n",
    "axn.matshow(conn, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conn.shape[0]):\n",
    "    for j in range(conn.shape[1]):\n",
    "        axn.text(x=j, y=i, s=conn[i,j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=10)\n",
    "plt.ylabel('Actuals', fontsize=10)\n",
    "plt.title('Confusion Matrix', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=1,kernel = 'rbf',gamma='auto')\n",
    "svc.fit(train_features,train_labels)\n",
    "preds = svc.predict(test_features)\n",
    "accuracys = svc.score(test_features,test_labels)\n",
    "cons = metrics.confusion_matrix(test_labels,preds)\n",
    "print('Accuracy = ', accuracys*100,'%')\n",
    "print(preds)\n",
    "print(test_labels)\n",
    "test_vs_pred(test_labels,preds)\n",
    "figs, axs = plt.subplots(figsize=(5,5))\n",
    "axs.matshow(cons, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cons.shape[0]):\n",
    "    for j in range(cons.shape[1]):\n",
    "        axs.text(x=j, y=i, s=cons[i,j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=10)\n",
    "plt.ylabel('Actuals', fontsize=10)\n",
    "plt.title('Confusion Matrix', fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7033a598c4e3dfb720271314b9986e8120e41fea5459a27e9c362ce2ab6a468c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
